# GSoC NIU Projects 2025

Below you can find our list of projects for GSoC 2025 (aka our "Ideas List"). 

<!-- There are three main milestones in a GSoC project: the community bonding period, the start of coding, and the coding end.

During the community bonding period, the GSoC contributor gets to know the community and participates in project discussions. They also prepare for their project, setting up their development environments, learning how their projectâ€™s source control works, refining their project plans, and reading any necessary documentation. 

The start of coding is the official start of the program and when the GSoC contributor starts executing on their project. The coding end is when the project is due. GSoC contributors are encouraged to continue work on their projects after the coding end, but only work done before this date can be evaluated. GSoC contributors will need to submit mentor evaluations and a link to their code. -->

A project can be one of three sizes: small (90 h), medium (175 h) or large  large (350 h). The standard coding period is 12 weeks for medium and large projects, and 8 weeks for small projects. 

However, GSoC contributors can request in their proposal up to a 22-week coding period, if they know they may have other commitments or certain weeks when they will not be able to work full time on their GSoC project. During the project preparation period (called "community bonding period"), both the GSoC contributor and the mentors will agree on a schedule and sign off on it.


If you are interested in any of these projects, feel free to reach out by opening a new topic on [Zulip](https://neuroinformatics.zulipchat.com/), and tagging the potential mentors.

::::{grid} 1 1 1 1
:gutter: 4

:::{grid-item-card} {fas}`video;sd-text-primary` Support for Kalman filters in `movement`
<!-- Description -->
Markerless pose estimation tools, such as [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and [SLEAP](https://sleap.ai/), have revolutionised the study of animal behaviour. However, there is currently no user-friendly, general-purpose approach for processing and analysing the trajectories generated by these popular tools. To fill this gap, we're developing [`movement`](https://movement.neuroinformatics.dev/), an open-source Python package that provides a unified data analysis interface across pose estimation frameworks. 

One of `movement`'s [priority features](https://movement.neuroinformatics.dev/community/roadmaps.html#long-term-vision) is to support versatile and efficient methods for data cleaning and filtering. To this aim, we would like to add support for applying Kalman filter in `movement`.

In its simplest implementation, we would like to be able to use Kalman filters to smooth position, velocity and acceleration timeseries. However, the same functionality could be expanded to other use cases, for example to fix identity switched between animals in multi-animal tracking data, or to improve point trajectory estimations by aggregating information from multiple sources. We are open to either implementing from scratch or wrapping an existing Python implementation. We would like to work with the GSoC contributor to design the best possible solution.


**Deliverables**
<!-- Goals, or expected status after Community Bonding Period, Start of Coding, End of Coding. Stretch goals? -->
The expected deliverables include:

- a Python implementation of a Kalman filter for smoothing position, velocity and acceleration timeseries,
- a Python implementation of a Kalman filter for fixing identity switches in multi-animal tracking data,
- tests to cover any added functionality,
- documentation for the new functionality,
- an example use case in the `movement` [gallery](https://movement.neuroinformatics.dev/examples/index.html).

**Duration**
<!-- Small (~90 hours), Medium (~175 hours) or Large (~350 hours)  -->
Medium (~175 hours).

**Difficulty**
<!-- Is this project geared more toward a student level or a more advanced developer level? -->
This project is well-suited for a student or a beginner contributor to open source.

**Required skills**

Experience with Python, [NumPy](https://numpy.org/doc/stable/index.html) and/or [pandas](https://pandas.pydata.org/docs/index.html).


**Nice-to-haves** 

- Experience with [xarray](https://docs.xarray.dev/en/stable/index.html) and [pytest](https://docs.pytest.org/en/stable/).
- Familiarity with pose estimation frameworks and their usual workflow ([DeepLabCut](https://www.mackenziemathislab.org/deeplabcut), [SLEAP](https://sleap.ai/), [idtracker](https://idtracker.ai/latest/)...)
- Experience or interest in digital signal processing methods, linear dynamical systems or state space modelling.

**Potential mentors**

- [@niksirbi](https://github.com/niksirbi)
- [@sfmig](https://github.com/sfmig)

**Further reading**
<!-- The best pages include links to more detailed descriptions and related materials for each project. They might even include actual use cases! -->
- `movement` [mission and scope](https://movement.neuroinformatics.dev/community/mission-scope.html#target-mission), [roadmap](https://movement.neuroinformatics.dev/community/roadmaps.html#target-roadmaps) and [contributing guide](https://movement.neuroinformatics.dev/community/contributing.html#target-contributing).
- [KalmanFilter.NET tutorial](https://www.kalmanfilter.net/default.aspx).
- An [example implementation](https://github.com/joacorapela/lds_python) in Python using linear dynamical systems for tracking.
- Python implementations of Kalman filters, such as [pykalman](https://github.com/pykalman/pykalman)
- State-space models packages with support for Kalman filters, such as [dynamax](https://movement.neuroinformatics.dev/examples/index.html), or time series analysis packages such as [darts](https://unit8co.github.io/darts/index.html).
:::

:::{grid-item-card} {fas}`video;sd-text-primary` Implementing outlier detection algorithms in `movement`

Markerless pose estimation tools, such as [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and [SLEAP](https://sleap.ai/), have revolutionised the study of animal behaviour. However, there is currently no user-friendly, general-purpose approach for processing and analysing the trajectories generated by these popular tools. To fill this gap, we're developing [`movement`](https://movement.neuroinformatics.dev/), an open-source Python package that provides a unified data analysis interface across pose estimation frameworks. 

A common issue with these pose estimation frameworks is that often they produce inaccurate results that are difficult to detect without manual inspection. For example, for a few frames, the bodypart of an animal may be incorrectly located in a position far from the rest of the bodyparts, leading to a "jerky" and unrealistic trajectory.

The goal of this project is to add functionality to easily detect such outlier keypoints, so that users can perform quality control on the predicted keypoints and remove or correct erroneous or implausible ones. Following the ideas implemented in the [LightningPose](https://github.com/paninski-lab/lightning-pose) framework, we would like to implement outlier detection methods following the heuristics below:
- *temporal smoothness*: often we can assume that the changes in position from frame `f` to frame `f+1` should be smooth. For example, if the animal is moving in a straight line, the position of the mean keypoint should not change abruptly. This is not always the case, for example eye or head movements, may be saccadic, but it does cover a large number of cases.
- *pose plausibility*: the position of the keypoints should be plausible given the context of the data collection. For example, if the animal is walking, the position of the keypoints should be consistent with the animal's body shape and the expected range of motion of the joints. One way to implement this constraint could be following LigthningPose's approach, which derives "plausibility" using principal component analysis - i.e. a pose is flagged as implausible if it lies outside a certain low-dimensional subspace.
- *multi-view consistency*: given two or more views of the same animal (e.g. using two cameras, or a camera and a mirror showing a different view), the two views of the same keypoint must be consistently "projectable" to some 3D subspace (computed for example with principal components analysis), because the true position of that keypoint must be a single point in 3D.

**Deliverables**
<!-- Goals, or expected status after Community Bonding Period, Start of Coding, End of Coding. Stretch goals? -->
The expected deliverables include:
- implementing an outlier detection module, with methods for temporal smoothness, pose plausibility and multi-view consistency,
- tests to cover any added functionality,
- documentation for the new functionality,
- an example use case in the `movement` [gallery](https://movement.neuroinformatics.dev/examples/index.html).

**Duration**
<!-- Small (~90 hours), Medium (~175 hours) or Large (~350 hours)  -->
Large (~350 hours)

**Difficulty**
<!-- Is this project geared more toward a student level or a more advanced developer level? -->
This project is well suited for an intermediate contributor to open source.

**Required skills**

Experience with Python, [NumPy](https://numpy.org/doc/stable/index.html) and/or [pandas](https://pandas.pydata.org/docs/index.html).


**Nice-to-haves**
- Experience with [xarray](https://docs.xarray.dev/en/stable/index.html) and [pytest](https://docs.pytest.org/en/stable/).
- Familiarity with pose estimation frameworks and their usual workflow (see for example [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut), [SLEAP](https://sleap.ai/) or [idtracker](https://idtracker.ai/latest/)).
- Experience or interest in digital signal processing methods, linear dynamical systems or state space modelling.


**Potential mentors**
- [@niksirbi](https://github.com/niksirbi)
- [@sfmig](https://github.com/sfmig)


**Further reading**
<!-- The best pages include links to more detailed descriptions and related materials for each project. They might even include actual use cases! -->
- `movement` [mission and scope](https://movement.neuroinformatics.dev/community/mission-scope.html#target-mission), [roadmap](https://movement.neuroinformatics.dev/community/roadmaps.html#target-roadmaps) and [contributing guide](https://movement.neuroinformatics.dev/community/contributing.html#target-contributing).
- LightningPose [paper](https://www.nature.com/articles/s41592-024-02319-1) and [codebase](https://github.com/paninski-lab/lightning-pose/blob/main/lightning_pose/losses/losses.py)

:::

:::{grid-item-card} {fas}`video;sd-text-primary` Calibrating confidence scores in `movement`

Markerless pose estimation tools, such as [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and [SLEAP](https://sleap.ai/), have revolutionised the study of animal behaviour. However, there is currently no user-friendly, general-purpose approach for processing and analysing the trajectories generated by these popular tools. To fill this gap, we're developing [`movement`](https://movement.neuroinformatics.dev/), an open-source Python package that provides a unified data analysis interface across pose estimation frameworks. 

Most pose estimation frameworks provide a confidence score for each keypoint, but these scores are often not well-calibrated, i.e. they do not reflect the true probability of the keypoint being correctly detected. It would be very useful to be able to produce calibrated confidence scores of the keypoint predictions. That would allow us to compare results across frameworks, better filter high/low confidence values, and better interpret model performance.

The goal of this project would be to implement a method to calibrate the confidence scores provided by the pose estimation frameworks supported in `movement`.

One approach to implement this could be similar to the one presented in [keypoint-moseq](https://github.com/dattalab/keypoint-moseq), where the confidence scores are calibrated using an interactive widget that fits a regression line to the log(confidence), log(error) pairs obtained through annotation. 

Another option could be to calibrate the confidence scores using a logistic regression model. The model is trained on a dataset of ground truth keypoints and the corresponding confidence scores, and then used to predict the true probability of the keypoint being correctly detected.

We are open to other suggestions and would like to work with the GSoC contributor to design together a good working solution.

**Deliverables**
<!-- Goals, or expected status after Community Bonding Period, Start of Coding, End of Coding. Stretch goals? -->
The expected deliverables include:
- a Python implementation of a method to calibrate the confidence scores provided by at least one of the pose estimation frameworks supported in `movement` (DeepLabCut, SLEAP, LightningPose, anipose),
- tests to cover any added functionality,
- documentation for the new functionality,
- an example use case in the `movement` [gallery](https://movement.neuroinformatics.dev/examples/index.html).


**Duration**
<!-- Small (~90 hours), Medium (~175 hours) or Large (~350 hours)  -->
Medium (~175 hours)

**Difficulty**
<!-- Is this project geared more toward a student level or a more advanced developer level? -->
This project is well-suited for a beginner or intermediate contributor to open source.

**Required skills**

Experience with Python, [NumPy](https://numpy.org/doc/stable/index.html) and/or [pandas](https://pandas.pydata.org/docs/index.html).

**Nice-to-haves**
- Experience with [xarray](https://docs.xarray.dev/en/stable/index.html) and [pytest](https://docs.pytest.org/en/stable/).
- Familiarity with pose estimation frameworks and their usual workflow (see for example [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut), [SLEAP](https://sleap.ai/) or [idtracker](https://idtracker.ai/latest/)).
- Experience with supervised machine learning methods and probability calibration.

**Potential mentors**
- [@niksirbi](https://github.com/niksirbi)
- [@sfmig](https://github.com/sfmig)


**Further reading**
<!-- The best pages include links to more detailed descriptions and related materials for each project. They might even include actual use cases! -->
There are nice explanations of the calibration issue for the case of classification (but note that in pose estimation we solve a regression problem, not a classification one):
- [Calibrating Neural Networks](https://geoffpleiss.com/blog/nn_calibration.html)
- [Scikit-learn: probability calibration](https://scikit-learn.org/stable/modules/calibration.html)
:::

:::{grid-item-card} {fas}`video;sd-text-primary` Web-based graphical interface for `movement`

Markerless pose estimation tools, such as [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut) and [SLEAP](https://sleap.ai/), have revolutionised the study of animal behaviour. However, there is currently no user-friendly, general-purpose approach for processing and analysing the trajectories generated by these popular tools. To fill this gap, we're developing [`movement`](https://movement.neuroinformatics.dev/), an open-source Python package that provides a unified data analysis interface across pose estimation frameworks. 


The goal of this project is to develop a prototype for a web-based graphical interface.

Designed for researchers of all coding levels, `movement` will feature an intuitive GUI, ensuring ease of use and broad accessibility. Our transparent, robust development process, backed by dedicated engineers, aims to make movement a comprehensive, all-around software suite for analysing animal behaviour.

https://movement.neuroinformatics.dev/community/mission-scope.html#design-principles


**Deliverables**
<!-- Goals, or expected status after Community Bonding Period, Start of Coding, End of Coding. Stretch goals? -->

**Duration**
<!-- Small (~90 hours), Medium (~175 hours) or Large (~350 hours)  -->

**Difficulty**
<!-- Is this project geared more toward a student level or a more advanced developer level? -->

**Required skills**

- Experience with Python, [NumPy](https://numpy.org/doc/stable/index.html) and/or [pandas](https://pandas.pydata.org/docs/index.html).

**Nice-to-haves**
- Experience with [xarray](https://docs.xarray.dev/en/stable/index.html) and [pytest](https://docs.pytest.org/en/stable/).
- Familiarity with pose estimation frameworks and their manual annotation workflow (see for example [DeepLabCut](https://www.mackenziemathislab.org/deeplabcut)or [SLEAP](https://sleap.ai/)).
- Experience developing data web apps in Python, with tools such as [Dash Plotly](https://dash.plotly.com/).
- Interest in data visualisation.


**Potential mentors**
- [@niksirbi](https://github.com/niksirbi)
- [@sfmig](https://github.com/sfmig)


**Further reading**
:::

:::{grid-item-card} {fas}`video;sd-text-primary` Front-end support for filtering module in `movement`

[`movement`](https://movement.neuroinformatics.dev/) is a Python toolbox for analysing animal body movements across space and time.

The goal of this project would be to add support for Kalman filters to the `movement` package, which is used to analyse behavioural data.

Designed for researchers of all coding levels, movement will feature an intuitive GUI, ensuring ease of use and broad accessibility. Our transparent, robust development process, backed by dedicated engineers, aims to make movement a comprehensive, all-around software suite for analysing animal behaviour.


**Deliverables**
<!-- Goals, or expected status after Community Bonding Period, Start of Coding, End of Coding. Stretch goals? -->

**Duration**
<!-- Small (~90 hours), Medium (~175 hours) or Large (~350 hours)  -->

**Difficulty**
<!-- Is this project geared more toward a student level or a more advanced developer level? -->

**Required skills**

**Nice-to-haves**

- Experience developing or using [napari](https://napari.org/) plugins.
- Interest in data visualisation.

**Potential mentors**

- [@niksirbi](https://github.com/niksirbi)
- [@sfmig](https://github.com/sfmig)


**Further reading**
:::

::::


