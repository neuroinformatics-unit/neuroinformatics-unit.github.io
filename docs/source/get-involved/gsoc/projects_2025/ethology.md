# GSoC NIU Projects 2025: `ethology`

Below you can find our list of projects for GSoC 2025 (aka our "Ideas List"). 

A project can be one of three sizes: small (90 h), medium (175 h) or large  large (350 h). The standard coding period is 12 weeks for medium and large projects, and 8 weeks for small projects. 

However, GSoC contributors can request in their proposal up to a 22-week coding period, if they know they may have other commitments or certain weeks when they will not be able to work full time on their GSoC project. During the project preparation period (called "community bonding period"), both the GSoC contributor and the mentors will agree on a schedule and sign off on it.

If you are interested in any of these projects, feel free to reach out by opening a new topic on [Zulip](https://neuroinformatics.zulipchat.com/), and tagging the potential mentors.


:::{dropdown} {fas}`video;sd-text-primary` Support for any-point trackers in `ethology`

The main goal of [`ethology`](https://github.com/neuroinformatics-unit/ethology) is to facilitate the application of a wide range of computer vision tasks to animal behaviour research, by providing a unified data analysis interface across these tasks. 

Any-point tracking is a good example of a computer vision task that is maturing within the field of computer vision, but it still relatively inaccessible to animal behaviour researchers. The task consists on the following: given a video and a set of query points on a frame of that video, predict the location of those points on every other frame of the video. This is a more general problem than the pose estimation one, which typically focuses on predicting the location of a fixed set of keypoints on an animal's body. As a result, any-point tracking tools could prove to be a very valuable tool for studying animal behaviour, with potential to supplement or potentially even replace pose estimation.


Depending on the quality of the trajectories generated by any-point trackers, these could be useful to study the movement patterns of animals directly, or they may be more helpful as a semi-automatic way to quickly generate labelled data. In recent years, there has been an increase in the development of any-point trackers, such as [cotracker3](https://cotracker3.github.io/) and [TAPIR](https://deepmind-tapir.github.io/blogpost.html). The goal of this project is to add support for any-point trackers to `ethology`, so that users can easily apply these tools to their data and analyse the trajectories generated.


**Deliverables**

<!-- Goals, or expected status after Community Bonding Period, Start of Coding, End of Coding. Stretch goals? -->
The expected deliverables include:
- A prototype [napari](https://napari.org/stable/) widget, that allows the user to load a video and select the query points to track. 
- Back-end functionality to read the query points from the napari widget, and run inference on a pre-trained any-point tracker model, such as those provided by [cotracker3](https://cotracker3.github.io/) or [TAPIR](https://deepmind-tapir.github.io/blogpost.html).
- Ability to read the generated trajectories as a `movement` [dataset](https://movement.neuroinformatics.dev/user_guide/movement_dataset.html).
- Front-end support on the napari widget to overlay the trajectories generated by the any-point tracker on the video.
- As a stretch goal, the widget could be extended to allow the user to run inference directly from the napari GUI.

**Duration**
<!-- Small (~90 hours), Medium (~175 hours) or Large (~350 hours)  -->
Large (~350 hours)

**Difficulty**
<!-- Is this project geared more toward a student level or a more advanced developer level? -->
This project is well-suited for an intermediate or advanced contributor to open source.

**Required skills**

Experience with Python and [PyTorch](https://pytorch.org/).

**Nice-to-haves**
- Experience developing or using [napari](https://napari.org/) plugins.
- Experience with computer vision applications, particularly pose estimation and any-point tracking approaches.


**Potential mentors**

- [@sfmig](https://github.com/sfmig)
- [@niksirbi](https://github.com/niksirbi)


**Further reading**
<!-- The best pages include links to more detailed descriptions and related materials for each project. They might even include actual use cases! -->
- [cotracker3 paper and code](https://cotracker3.github.io/)
- [TAPIR paper and code](https://deepmind-tapir.github.io/blogpost.html)
- [napari usage tutorials](https://napari.org/stable/tutorials/index.html) and [contributing guide](https://napari.org/stable/developers/contributing/index.html).
- [napari Plugin documentation](https://napari.org/stable/plugins/index.html), particularly the section on [Building a plugin](https://napari.org/stable/plugins/building_a_plugin/index.html).
:::


